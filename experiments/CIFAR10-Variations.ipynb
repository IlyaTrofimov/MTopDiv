{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image as im\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from scipy import stats\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), AddGaussianNoise(0, 0.1)])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "\n",
    "def imshow(img):\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show imagesz\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(images.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rlts(X):\n",
    "    N = 2500\n",
    "    gamma = (1/128)/(N/5000)\n",
    "    rlts = gs.rlts(X, gamma=gamma, n=N, n_threads = 40)\n",
    "    \n",
    "    return rlts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "labels_idx = [None] * 50000\n",
    "\n",
    "for image, label in trainloader:\n",
    "    labels_idx[idx] = label.item()\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_with_label(cl):\n",
    "    idx_with_label = list(filter(lambda x : x[1] == cl, list(enumerate(labels_idx))))\n",
    "    idx_with_label = [x[0] for x in idx_with_label]\n",
    "    \n",
    "    return idx_with_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statified(num):\n",
    "    \n",
    "    idx = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        idx.extend(get_idx_with_label(i)[0:num])\n",
    "        \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_statified(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar10_filtered(allowed_labes = set(range(10)), transforms_list = [], train = True):\n",
    "    \n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor()] + transforms_list)\n",
    "    \n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=train,\n",
    "                                        download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=False, num_workers=1)\n",
    "    for image, label in trainloader:\n",
    "        if label.item() in allowed_labes:\n",
    "            yield image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_idx = list(range(50000))\n",
    "\n",
    "np.random.seed(7)\n",
    "np.random.shuffle(all_idx)\n",
    "ten_thousands_idx = set(all_idx[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dir(adir, allowed_labels, selected_idx = None, transforms_list = [], train = True, max_cnt = None):\n",
    "    os.system('rm -rf %s' % adir)\n",
    "    os.mkdir(adir)\n",
    "    \n",
    "    idx = 0\n",
    "    X = []\n",
    "    \n",
    "    for image, label in cifar10_filtered(allowed_labels, transforms_list, train):\n",
    "        if selected_idx:\n",
    "            if not (idx in selected_idx):\n",
    "                idx += 1\n",
    "                continue\n",
    "                \n",
    "        if max_cnt:\n",
    "            if idx == max_cnt:\n",
    "                break\n",
    "                \n",
    "        npimg = image.numpy().mean(axis = 0)\n",
    "        png_data = im.fromarray((255*np.transpose(npimg, (1, 2, 0))).astype('uint8'))\n",
    "        path = '%s/%d.png' % (adir, idx)\n",
    "        png_data.save(path)\n",
    "        X.append(npimg.flatten())\n",
    "        idx += 1\n",
    "        \n",
    "    print('num points', len(X))\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(func_exp):\n",
    "    \n",
    "    rlts = []\n",
    "    res = []\n",
    "    i = 0\n",
    "    \n",
    "    for X_base, X in func_exp():\n",
    "        \n",
    "        archive.append((X_base, X))\n",
    "        \n",
    "        if not rlts:\n",
    "            rlts.append(get_rlts(X_base))\n",
    "\n",
    "        rlts.append(get_rlts(X))\n",
    "        cmd = 'pytorch-fid tmp1 tmp2 --device cuda:1'\n",
    "        res_str = subprocess.run(cmd.split(' '), capture_output=True, text=True).stdout\n",
    "        \n",
    "        res.append((i, res_str))\n",
    "        i+= 1\n",
    "        \n",
    "    return res, rlts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q95(rlts_base, rlts):\n",
    "    mean_base = np.mean(rlts_base, axis = 0)\n",
    "\n",
    "    gs_base = []\n",
    "    \n",
    "    for i in range(1000):\n",
    "        rlts2 = sklearn.utils.resample(rlts_base)\n",
    "        \n",
    "        mrlt1 = mean_base\n",
    "        mrlt2 = np.mean(rlts2, axis=0)\n",
    "        gs_base.append(np.sum((mrlt1 - mrlt2) ** 2))\n",
    "        \n",
    "    \n",
    "    idx = int(len(gs_base)*0.95)\n",
    "    q95 = sorted(list(gs_base))[idx]\n",
    "\n",
    "    return 1e3 * q95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stat(rlts):\n",
    "    \n",
    "    print('q95', get_q95(rlts[0], None))\n",
    "    print()\n",
    "    \n",
    "    for i in range(1, len(rlts)):\n",
    "        print(1e3 * gs.geom_score(rlts[0], rlts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mode_drop_exp():\n",
    "    all_labels = set(range(10))\n",
    "    X_base = write_dir('tmp1', all_labels, train = False)\n",
    "\n",
    "    for i in range(5):\n",
    "        X = write_dir('tmp2', all_labels, max_cnt = 10000)\n",
    "        all_labels.remove(i)\n",
    "        \n",
    "        yield X_base, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_drop, rlts_drop = run_exp(mode_drop_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stat(rlts_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode drop by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_drop_exp2():\n",
    "    all_labels = set(range(10))\n",
    "    X_base = write_dir('tmp1', all_labels, train = False)\n",
    "\n",
    "    for i in range(10):\n",
    "        X = write_dir('tmp2', all_labels.difference(set([i])), max_cnt = 10000)\n",
    "        yield X_base, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_drop2, rlts_drop2 = run_exp(mode_drop_exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_drop2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stat(rlts_drop2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode invention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_invention_exp():\n",
    "    X_base = write_dir('tmp1', set(range(5)), train = False)\n",
    "    new_labels = set(range(5))\n",
    "    \n",
    "    for i in range(5, 10):\n",
    "        X = write_dir('tmp2', new_labels, max_cnt = 5000)\n",
    "        new_labels.add(i)\n",
    "        \n",
    "        yield X_base, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_invention, rlts_invention = run_exp(mode_invention_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_invention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stat(rlts_invention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intra-mode collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intra_mode_collapse_exp():\n",
    "    all_labels = set(range(10))\n",
    "    X_base = write_dir('tmp1', all_labels, train = False)\n",
    "\n",
    "    for c in [1, 10, 100, 1000]:\n",
    "        X = write_dir('tmp2', all_labels, get_statified(c))\n",
    "        yield X_base, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_intra, rlts_intra = run_exp(intra_mode_collapse_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_intra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stat(rlts_intra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Erase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_erase_exp():\n",
    "    all_labels = set(range(10))\n",
    "    X_base = write_dir('tmp1', all_labels, train = False)\n",
    "\n",
    "    for ascale in [0.0, 0.01, 0.05, 0.25]:\n",
    "        random_erase = [transforms.RandomErasing(scale = (ascale, ascale))]\n",
    "        X = write_dir('tmp2', all_labels, transforms_list = random_erase, max_cnt = 10000)\n",
    "        \n",
    "        yield X_base, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_erase, rlts_erase = run_exp(random_erase_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_erase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stat(rlts_erase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise_exp():\n",
    "    all_labels = set(range(10))\n",
    "    X_base = write_dir('tmp1', all_labels, train = False)\n",
    "\n",
    "    for sigma in [0.0, 0.01, 0.02, 0.04, 0.08]:\n",
    "        random_erase = [AddGaussianNoise(0, sigma)]\n",
    "        X = write_dir('tmp2', all_labels, transforms_list = random_erase, max_cnt = 10000)\n",
    "        \n",
    "        yield X_base, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gauss, rlts_gauss = run_exp(gaussian_noise_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stat(rlts_gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(archive, open('archive_v2.pickle', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
