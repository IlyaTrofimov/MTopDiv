{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import pathlib\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = torch.load('/gan-clouds/datasets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds = {'dcgan': torch.load('/gan-clouds/DCGAN-2.pt'),\n",
    "          'lsgan' : torch.load('/gan-clouds/LSGAN-2.pt'),\n",
    "          'rel': torch.load('/gan-clouds/Relativistic-2.pt'),\n",
    "          'wgan': torch.load('/gan-clouds/WGAN.pt'),\n",
    "          'wgan-gp': torch.load('/gan-clouds/WGAN-GP.pt')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['cifar10'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = clouds['dcgan']['cifar10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mtd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, elem in enumerate(datasets['cifar10']):\n",
    "    data = elem.reshape((3, 32, 32)).astype('uint8')\n",
    "    data = np.transpose(data, (1, 2, 0))\n",
    "    png_data = Image.fromarray(data)\n",
    "    if idx == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, elem in enumerate(clouds['wgan']['cifar10']):\n",
    "    data = elem.reshape((3, 32, 32)).astype('uint8')\n",
    "    data = np.transpose(data, (1, 2, 0))\n",
    "    png_data = Image.fromarray(data)\n",
    "    if idx == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, elem in enumerate(datasets['mnist']):\n",
    "    data = elem.reshape((32, 32)).astype('uint8')\n",
    "    data_new = np.zeros((3, 32, 32), 'uint8')\n",
    "\n",
    "    for i in range(3):\n",
    "        data_new[i, :, :] = data\n",
    "        \n",
    "    data = data_new\n",
    "    \n",
    "    data = np.transpose(data, (1, 2, 0))\n",
    "    png_data = Image.fromarray(data)\n",
    "    if idx == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dir(adir, cloud, shape = (3, 32, 32), copy_channels = False):\n",
    "    os.system('rm -rf %s' % adir)\n",
    "    os.mkdir(adir)\n",
    "    \n",
    "    global gd\n",
    "    \n",
    "    for idx, elem in enumerate(cloud):\n",
    "        data = elem.reshape(shape).astype('uint8')\n",
    "        \n",
    "        if copy_channels:\n",
    "            data_new = np.zeros((3, 32, 32), 'uint8')\n",
    "\n",
    "            for i in range(3):\n",
    "                data_new[i, :, :] = data\n",
    "        \n",
    "            data = data_new\n",
    "        \n",
    "        #print(data.shape)\n",
    "        \n",
    "        data = np.transpose(data, (1, 2, 0))\n",
    "        png_data = Image.fromarray(data)\n",
    "        \n",
    "        #png_data\n",
    "        \n",
    "        path = '%s/%d.png' % (adir, idx)\n",
    "        png_data.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d in datasets.keys():\n",
    "    \n",
    "    print()\n",
    "    print(d)\n",
    "    print()\n",
    "    \n",
    "    for g in clouds.keys():\n",
    "        if d in ['mnist', 'fashion_mnist']:\n",
    "            shape = (32, 32)\n",
    "            copy_channels = True\n",
    "        if d in ['cifar10', 'svhn']:\n",
    "            shape = (3, 32, 32)\n",
    "            copy_channels = False\n",
    "            \n",
    "        if g not in ['wgan', 'wgan-gp']:\n",
    "            continue\n",
    "        \n",
    "        write_dir('tmp1', datasets[d], shape, copy_channels = copy_channels)\n",
    "        write_dir('tmp2', clouds[g][d], shape, copy_channels = copy_channels)\n",
    "\n",
    "        cmd = 'pytorch-fid tmp1 tmp2 --device cuda:0'\n",
    "        res_str = subprocess.run(cmd.split(' '), capture_output=True, text=True).stdout\n",
    "\n",
    "        print(g, res_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MTopDiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res1 = {}\n",
    "trials = 200\n",
    "\n",
    "for d in datasets.keys():\n",
    "    base_cloud = datasets[d]\n",
    "    for g in clouds.keys():\n",
    "        mod_cloud = clouds[g][d]\n",
    "\n",
    "        np.random.seed(7)\n",
    "        barcs = [mtd.calc_cross_barcodes(mod_cloud, base_cloud, batch_size1 = 100, batch_size2 = 1000, cuda = 3) for _ in range(trials)]\n",
    "        \n",
    "        res1[(d, g)] = barcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res2 = {}\n",
    "trials = 200\n",
    "\n",
    "for d in datasets.keys():\n",
    "    base_cloud = datasets[d]\n",
    "    for g in clouds.keys():\n",
    "        mod_cloud = clouds[g][d]\n",
    "\n",
    "        np.random.seed(7)\n",
    "        barcs = [mtd.calc_cross_barcodes(base_cloud, mod_cloud, batch_size1 = 100, batch_size2 = 1000, cuda = 3) for _ in range(trials)]\n",
    "        \n",
    "        res2[(d, g)] = barcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(res, args_dict, trials = 10):\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    for k in sorted(res.keys()):\n",
    "        asum = []\n",
    "        \n",
    "        for exp_id, elem in enumerate(res[k]):\n",
    "            asum.append(mtd.get_score(elem, **args_dict))\n",
    "\n",
    "        scores[k] = np.mean(asum), np.std(asum) / sqrt(len(asum))\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in datasets.keys():\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = get_scores(res2, {'h_idx' : 1, 'kind' : 'sum_length'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for d in ['cifar10']:\n",
    "    for g in clouds.keys():\n",
    "\n",
    "        k = (d, g)\n",
    "        \n",
    "        sys.stdout.write(str(scores[k][0]).replace('.', ',') + ' ')\n",
    "        \n",
    "    sys.stdout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional experiments with IMD\n",
    "\n",
    "from msid import msid_score\n",
    "\n",
    "res = {}\n",
    "\n",
    "for d in tqdm(datasets.keys()):\n",
    "    base_cloud = datasets[d]\n",
    "    for g in clouds.keys():\n",
    "        mod_cloud = clouds[g][d]\n",
    "\n",
    "        indices = list(range(len(base_cloud)))\n",
    "        np.random.seed(7)\n",
    "        np.random.shuffle(indices)\n",
    "        rnd_idx = indices[0:5000]\n",
    "        \n",
    "        res[(d, g)] = msid_score(base_cloud[rnd_idx], mod_cloud[rnd_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CHECKING CORRECTNESS')\n",
    "print('--------------------')\n",
    "print('cifar10', res[('cifar10', 'wgan')] < res[('cifar10', 'wgan-gp')])\n",
    "print('svhn', res[('svhn', 'wgan')] < res[('svhn', 'wgan-gp')])\n",
    "print('mnist', res[('mnist', 'wgan')] > res[('mnist', 'wgan-gp')])\n",
    "print('fashion_mnist', res[('fashion_mnist', 'wgan')] > res[('fashion_mnist', 'wgan-gp')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
